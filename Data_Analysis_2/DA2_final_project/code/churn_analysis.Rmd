---
title: "Churn Prediction -  PowerCo."
author: "Fasih Atif"
output: pdf_document
header-includes:
  - \usepackage{titling}
  - \setlength{\droptitle}{-5em}
---

Define what is your (broad) research question! What you want to learn from the data or what you want to use it? (a) What is the main aim: prediction or causality?

```{r load_libraries, include= FALSE}
##########################################
#               Load libraries           #
##########################################
library(tidyverse)
library(data.table)
library(lubridate)
library(fastDummies)   # To create fummy variables
library(estimatr)
library(scales)        # To take logs of x and y variables
library(faraway)
library(caret)
library(car)           # To calculate VIF
library(corrplot)      # To draw correlation chart
library(outForest)
library(xgboost)
library(Ckmeans.1d.dp) # Required for xgb.ggplot.importance function in xgboost
library(randomForest)
library(Metrics)       # To calculate AUC
library(ggpubr)
library(knitr)
```

```{r data_import, include= FALSE}
##########################################
#             Data Import                #
##########################################

# Import CustomerHistory.csv
urlCustomerHistory <- 'https://raw.githubusercontent.com/fasihatif/Data-Analysis-1-2-3/master/Data_Analysis_2/DA2_final_project/data/CustomerDetails.csv'
DfCustomerHistory <- read_csv(urlCustomerHistory)

# Import PricingHistory.csv
urlPricingHistory <- 'https://raw.githubusercontent.com/fasihatif/Data-Analysis-1-2-3/master/Data_Analysis_2/DA2_final_project/data/PricingHistory.csv'
DfPricingHistory <- read_csv(urlPricingHistory)

# Import ChurnOutput.csv
urlChurnOutput <- 'https://raw.githubusercontent.com/fasihatif/Data-Analysis-1-2-3/master/Data_Analysis_2/DA2_final_project/data/ChurnOutput.csv'
DfChurnOutput <- read_csv(urlChurnOutput)
```

## **Understanding our Data**

```{r merge_data, include= FALSE}

# Number of rows in DfCustomerHistory
count(unique(DfCustomerHistory)) #16096

# Number of rows in DfChurnOutput
count(unique(DfChurnOutput)) #16096

# Merge dataframes by id column since equal and has unique ids. We create a df named df_draft where we do all the working for cleaning and feature engineering
df_draft <- merge(DfCustomerHistory,DfChurnOutput, by = 'id')
write.csv(df_draft, "df_draft.csv")

rm(DfChurnOutput,DfCustomerHistory)

# Get stats of each column
summary(df_draft) # add some analysis regarding consumption and forecasting

```

```{r data_cleaning, include= FALSE}
##########################################
#             Cleaning the Data          #
##########################################

# Number of missing values in each column
na_count <- sapply(df_draft, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)

# Number of missing values in percent in each column. 
# We will check which columns have missing values greater than 30% and drop them. We will also ensure that the columns to be dropped dont contain any important information inw hich case we wont drop them.
na_count$na_percent <- sapply(df_draft, function(y) round((sum(length(which(is.na(y))))/length(y))*100.00,2))

# Save the names of columns which have missing values less than 30%
col_30 <- na_count %>% filter(na_percent < 30)
col_30 <- rownames(col_30)

# Remove columns with NA values greater than 30%
df_draft <- df_draft %>% select(all_of(col_30))

# Fill in missing dates with median
## Replace NA values in 'date_end' column with median date
df_draft$date_end[is.na(df_draft$date_end)]<-median(df_draft$date_end,na.rm=TRUE)

##Replace NA values in 'date_renewal' column with median date
df_draft$date_renewal[is.na(df_draft$date_renewal)]<-median(df_draft$date_renewal,na.rm=TRUE)

## Replace NA values in 'date_modif_prod' column with median date
df_draft$date_modif_prod[is.na(df_draft$date_modif_prod)]<-median(df_draft$date_modif_prod,na.rm=TRUE)

## Replace NA values in channel sales column with 'null_channel'
df_draft$channel_sales[is.na(df_draft$channel_sales)] <- "null_channel"

# Convert 'has_gas' column from T/F to 1/0
df_draft <- df_draft %>% mutate('has_gas' =  as.numeric(has_gas))
```

```{r feature_engineering, include= FALSE}
##########################################
#            Feature Engineering         #
##########################################

# Create 'contract duration' column and divide by 365 to get yearly values
df_draft <- df_draft %>% mutate('contract_duration' =  as.integer((difftime(date_end,date_activ, unit = "days"))/(365.25/12)))

# Create reference date for calculations. We will take 1st Jan 2020 since it is given as the reference date
ref_date = ymd(20160101)

# No of years since contract went active
df_draft <- df_draft %>% mutate('months_active' =  as.integer((difftime(ref_date,date_activ, unit = "days"))/(365.25/12)))

# No of years left in contract
df_draft <- df_draft %>% mutate('months_end' =  as.integer((difftime(date_end,ref_date, unit = "days"))/(365.25/12)))

# No of years since last modification at reference date
df_draft <- df_draft %>% mutate('months_modif' =  as.integer((difftime(ref_date,date_modif_prod, unit = "days"))/(365.25/12)))

# Number of months since last renewal at reference date
df_draft <- df_draft %>% mutate('months_renewal' =  as.integer((difftime(ref_date,date_renewal, unit = "days"))/(365.25/12)))

# Remove columns with NA values greater than 30%
df <- df_draft %>% select(all_of(col_30), contract_duration,has_gas,months_active,months_end,months_modif,months_renewal)
df <- df %>% select(-c(date_activ,date_end,date_modif_prod,date_renewal, date_renewal,forecast_cons_year, origin_up))

# Dummy Variable creation for channel_sales and has_gas
## How many dummy columns to make?
# df_backup <- df

df %>% 
  group_by(channel_sales) %>%
  summarize(channel_count = n()) # 8 unique channels so we will make 8 dummy columns

## Create dummy variables using the fastdummies library
df <- df %>% dummy_cols(select_columns = c("channel_sales","has_gas"), remove_selected_columns = TRUE)

## Updating column names of dummy variables for easier understanding
df <- df %>% 
  rename(
    "channel_foos" = channel_sales_foosdfpfkusacimwkcsosbicdxkicaua,
    "channel_usil" = channel_sales_usilxuppasemubllopkaafesmlibmsdf,
    "channel_lmke" = channel_sales_lmkebamcaaclubfxadlmueccxoimlema,
    "channel_ewpa" = channel_sales_ewpakwlliwisiwduibdlfmalxowmwpci,
    "channel_epum" = channel_sales_epumfxlbckeskwekxbiuasklxalciiuu,
    "channel_sddi" = channel_sales_sddiedcslfslkckwlfkdpoeeailfpeds,
    "channel_fixd" = channel_sales_fixdbufsefwooaasfcxdxadsiekoceaa,
    "channel_null" = channel_sales_null_channel
  )

## Remove one of the dummy columns to cater for multicollinearity. We will remove 'channel_null' and 'has_gas_0'
df <- subset(df,select = -c(channel_null,has_gas_0))

```

The raw data consisted of 33 columns and 16096 observations in each column. The data represents the several characteristics of the company that could play an important part in their churning and retention. The data contains variables such as dates, forecasted consumption and prices, net/gross margins and churn status. It is often said that 80% of the time is spent in data cleaning and processing while just 20% is spent on running the analytics on the clean data. This saying was applicable in our case as well. There were several data quality issues such as missing values, outliers, wrong negative values, multicollinearity, and skewed variables. Our dependent variable would be the binary churn variable while the rest of the variables would act as the independent variables.

## **Exploring Data Analysis**

```{r eda, include= FALSE}
# Churn Rate
churn_rate_barchart <- df %>% 
  select(churn) %>%
  group_by(churn) %>%
  summarise(percentage = n()) %>%
  mutate(Percent = round(100*percentage/sum(percentage),1)) %>%
  mutate(status = ifelse(churn == 1, "Churned", "Retention")) %>%
  ggplot(aes(x = "Companies", y = Percent, fill= factor(status, levels=c("Churned","Retention")))) +
  geom_bar(stat = "identity") + geom_text(aes(label = Percent), position = position_stack(vjust = .5)) +
  labs(x = '', fill = "Status")


# Function to calculate no of months in the duration between a date column and reference date
months_length <- function(column1, column2){
  
  dataframe <- data.frame(column1, column2)
  
  bar_chart <- dataframe %>%
    group_by(column1, column2) %>%
    summarise(months_count = n()) %>%
    mutate(status = ifelse(column2 == 1, "Churned", "Retention")) %>%
    ggplot(aes(x = column1, y = months_count, fill= factor(status))) +
    geom_bar(stat = "identity") + theme_bw() +
    labs(x = NULL, y = NULL,fill = "Status")
  
  return(bar_chart)
}

# Duration of contract
contract_duration_barchart <- months_length(df$contract_duration,df$churn)

# No of months passed from contract active date to reference date
months_active_barchart <- months_length(df$months_active,df$churn)

# No of months left till end date from reference date
months_end_barchart <- months_length(df$months_end,df$churn)

# No of months left till renewal from reference date
months_renewal_barchart <- months_length(df$months_renewal,df$churn)

# No of months since contract was last modified 
months_modif_barchart <- months_length(df$months_modif,df$churn)

##### CONSUMPTION VARIABLES EXPLORATORY ANALYSIS #####

color <- "cyan3"
consumption_eda <- df %>%
  select(cons_12m,cons_gas_12m,cons_last_month,imp_cons) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") +
  geom_histogram(fill = color) + theme_bw() +labs(y = NULL, x = NULL)


##### FORECAST VARIABLES EXPLORATORY ANALYSIS #####

forecast_eda <- df %>%
  select(forecast_cons_12m,forecast_discount_energy,forecast_meter_rent_12m,forecast_price_energy_p1,forecast_price_energy_p2,forecast_price_pow_p1) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") +
  geom_histogram(fill = color) + theme_bw() +labs(y = NULL, x = NULL)

##### MARGIN VARIABLES EXPLORATORY ANALYSIS #####

margin_eda <- df %>%
  select(margin_gross_pow_ele,margin_net_pow_ele,net_margin) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") +
  geom_histogram(fill = color) + theme_bw() +labs(y = NULL, x = NULL)

##### OTHER VARIABLES EXPLORATORY ANALYSIS #####

other_eda <- df %>%
  select(nb_prod_act,num_years_antig,pow_max) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") +
  geom_histogram(fill = color) + theme_bw() +labs(y = NULL, x = NULL)

```

```{r loess, include = FALSE, warning = FALSE, message = FALSE}

# Non Parametric Charts
# cons_12m
cons_12m_sc <- ggplot(df , aes(x = cons_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "cons_12m",y = "Churn", title = "Level - Level for churn~cons_12m") 

ln_cons_12m_sc <- ggplot(df , aes(x = cons_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "cons_12m, ln scale",y = "Churn", title = "Level - log for churn~ln_cons_12m") + 
  scale_x_continuous(trans = log_trans())

# cons_last_month
cons_last_month_sc <- ggplot(df , aes(x = cons_last_month, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "cons_last_month",y = "Churn", title = "Level - Level for churn~cons_last_month") 

ln_cons_last_month_sc <- ggplot(df , aes(x = cons_last_month, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "cons_last_month, ln scale",y = "Churn", title = "Level - log for churn~ln_cons_last_month") + 
  scale_x_continuous(trans = log_trans())

# imp_cons
imp_cons_sc <- ggplot(df , aes(x = imp_cons, y = churn)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(x = "imp_cons",y = "Churn", title = "Level - Level for churn~imp_cons") 

ln_imp_cons_sc <- ggplot(df , aes(x = imp_cons, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "imp_cons, ln scale",y = "Churn", title = "Level - log for churn~ln_imp_cons") + 
  scale_x_continuous(trans = log_trans())

# cons_gas_12m
cons_gas_12m_sc <- ggplot(df , aes(x = cons_gas_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(x = "cons_gas_12m",y = "Churn", title = "Level - Level for churn~cons_gas_12m") 

ln_cons_gas_12m_sc <- ggplot(df , aes(x = cons_gas_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "cons_gas_12m, ln scale",y = "Churn", title = "Level - log for churn~ln_cons_gas_12m") + 
  scale_x_continuous(trans = log_trans())

# forecast_cons_12m
forecast_cons_12m_sc <- ggplot(df , aes(x = forecast_cons_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(x = "forecast_cons_12m",y = "Churn", title = "Level - Level for churn~forecast_cons_12m") 

ln_forecast_cons_12m_sc <- ggplot(df , aes(x = cons_gas_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "forecast_cons_12m, ln scale",y = "Churn", title = "Level - log for churn~ln_forecast_cons_12m") + 
  scale_x_continuous(trans = log_trans())

# forecast_meter_rent_12m
forecast_meter_rent_12m_sc <- ggplot(df , aes(x = forecast_meter_rent_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(x = "forecast_meter_rent_12m",y = "Churn", title = "Level - Level for churn~forecast_meter_rent_12m") 

ln_forecast_meter_rent_12m_sc <- ggplot(df , aes(x = forecast_meter_rent_12m, y = churn)) +
  geom_point() +
  geom_smooth(method="loess")+
  labs(x = "forecast_meter_rent_12m, ln scale",y = "Churn", title = "Level - log for churn~ln_forecast_meter_rent_12m") + 
  scale_x_continuous(trans = log_trans())
```

```{r further_data_cleaning, include = FALSE}

# Subsetting important variables for outlier treatment
# df <- subset(df,select = -c(id,cons_12m,cons_gas_12m,cons_last_month,imp_cons,forecast_cons_12m,forecast_meter_rent_12m))
df_other <- df %>% select(-c(forecast_price_energy_p1,forecast_price_energy_p2,forecast_price_pow_p1,margin_gross_pow_ele,margin_net_pow_ele,net_margin,pow_max,cons_12m,cons_gas_12m,cons_last_month,imp_cons,forecast_cons_12m,forecast_meter_rent_12m))
df <- df %>% select(c(forecast_price_energy_p1,forecast_price_energy_p2,forecast_price_pow_p1,margin_gross_pow_ele,margin_net_pow_ele,net_margin,pow_max,cons_12m,cons_gas_12m,cons_last_month,imp_cons,forecast_cons_12m,forecast_meter_rent_12m))

# Detecting outliers and replacing them with mean
remove_outliers <- function(column_name){
  outliers <- boxplot(column_name, plot=FALSE)$out
  if(length(outliers) == 0){ column_name  <- column_name} else{
    column_name[column_name %in% outliers] = mean(column_name,na.rm = TRUE); column_name
  }
}

# Application of outlier function
df <- data.frame(sapply(df, remove_outliers))

# Join the treated dataset with rest of variables
df <- cbind(df_other,df)

# Continue on with df dataframe and treat it for missing values
# Remove all NA values and replace with mean

df_id <- df %>% select(id)
df <- df %>% select(-id)

# Save to new dataframe 'xgb_data'. The NA values in this table wont be treated for missing values as XGBoost can handle missing values internally
df_xgb <- df

df <- data.frame(sapply(df, function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))))

rm(df_other)

```

```{r transformation, include=FALSE, message=FALSE, warning=FALSE}
##########################################
#        Transformation of data          #
##########################################
##### Transformation of Consumption variables #####

# Consumption variables are right skewed as we saw from the histograms. To make them normally distributed, we will
# take log of these variables. However, these 4 variables include negative and zero values for which log cant be taken.So 
# we will convert negative values to NaN and add a constant 1 to these variables as well

# Set negative values as Na as log cant be taken for negative values
df <- df %>% mutate(cons_12m = replace(cons_12m, which(cons_12m < 0), NA))
df <- df %>% mutate(cons_gas_12m = replace(cons_gas_12m, which(cons_gas_12m < 0), NA))
df <- df %>% mutate(cons_last_month = replace(cons_last_month, which(cons_last_month < 0), NA))
df <- df %>% mutate(imp_cons = replace(imp_cons , which(imp_cons  < 0), NA))

# Add constant 1 to the variables and then take log
df <- df %>% mutate( ln_cons_12m = log( cons_12m + 1 ),
                     ln_cons_gas_12m = log( cons_gas_12m + 1),
                     ln_cons_last_month = log(cons_last_month + 1),
                     ln_imp_cons = log(imp_cons + 1)) 

summary(df$cons_12m)

##### Transformation of Forecast variables #####

# Set negative values as NaN as log cant be taken for negative values
df <- df %>% mutate(forecast_cons_12m = replace(forecast_cons_12m, which(forecast_cons_12m < 0), NA))
df <- df %>% mutate(forecast_meter_rent_12m = replace(forecast_meter_rent_12m, which(forecast_meter_rent_12m < 0), NA))


# Add constant 1 to the variables and then take log
df <- df %>% mutate( ln_forecast_cons_12m = log(forecast_cons_12m + 1),
                     ln_forecast_meter_rent_12m = log(forecast_meter_rent_12m + 1)) 

# backup2 <- df

# Now check for the distribution of the transformed variables
transformed_eda <- df %>%
  select(ln_cons_12m,ln_cons_gas_12m,ln_cons_last_month,ln_imp_cons,ln_forecast_cons_12m,ln_forecast_meter_rent_12m) %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~key, scales = "free") +
  geom_histogram(fill = color) + theme_bw() +labs(y = NULL, x = NULL)

# Remove original columns which have been transformed
df <- df %>% select(-c(cons_12m,cons_gas_12m,cons_last_month,imp_cons,forecast_cons_12m,forecast_meter_rent_12m))


```

```{r correlation_matrix, include = FALSE}
##### Correlation Matrix #####

cor1 <- cor(df, use = "pairwise.complete.obs")
cor_matrix <- ggcorrplot::ggcorrplot(cor1, method = "square",lab = TRUE, type = "lower", lab_size = 2.5, digits = 2,ggtheme = theme_bw)

# From the correlation matrix, we can see that 'contract_duration'& 'month_activ','num_years_antig' & 'months_end', 'margin_gross_power_ele' & 'margin_net_power_ele' have the highest correlation
# Calculate Variance Inflation Factor using the 'car' package
lm_model <- lm(churn ~ ., data = df)
vif <- data.frame(car::vif(lm_model))
vif <- rename(vif, VIF = car..vif.lm_model.)

# From the VIF we can confirm that the correlations are very high and we can drop one of the variables from each correlation pair.
df <- subset(df, select = -c(contract_duration,num_years_antig, margin_gross_pow_ele))
df_xgb <- subset(df_xgb, select = -c(contract_duration,num_years_antig, margin_gross_pow_ele))

```

The missing data (**Table 1**) was very small for majority of the variables, so we were able to easily replace the missing values with mean and median approximations.Any column that had more than 30% missing observations were removed. We then conducted Feature Engineering. We converted dates into durations to make them more useful. After getting done with our initial data cleaning and feature Engineering, we checked the distributions of the variables through histograms (**Figure 1-7**).

Our exploratory data analysis shows that around 10% of the of total customers have churned (**Figure 1**). All Consumption related variables (cons\_12m ,cons\_last\_month,imp\_conscons\_gas\_12m ) and 2 of the forecast variables (forecast\_cons\_12m,forecast\_meter\_rent\_12m) are extremely right skewed (**Figure 2,3**).The values on the higher end and lower ends of the distribution are potentially outliers. Next we checked a non-parametric estimator lowess smoother to have a general idea about the functional form between a variable and churn. We will specifically focus on those variables who had skewed distributions (Figure . As expect the functional forms are very non linear and hence we took log of the 6 variables( 4 consumption and 2 forecast variables) to give the loess line a more linear shape (**Figure 7**). The transformation of the log variables can be seen in (**Figure 8**).

We used boxplots to tell us more about the outliers and what their values are. We then removed these values and replaced them with the mean of the respective columns values excluding the outliers.

**5. Multicollinearity and Dummy Variables**

When you have two independent variables that are very highly correlated, you definitely should remove one of them because you run into the multicollinearity conundrum and your regression model's regression coefficients related to the two highly correlated variables will be unreliable. We checked for multicollinearity between the explanatory variables. We drew a correlated matrix (**Figure 9**) to observe which pair of variables were highly correlated. Once we found the pairs, we calculated the Variance Inflation Factor (VIF) (**Table 2**) to confirm the correlation and remove one variable from the pairs.This was done to reduce multicollinearity. For this, we first created the correlation matrix. For pairs that have very high correlations, we will use Variance Inflation Factor to determine which variable to remove. Categorical columns ('channel\_sales' and 'has\_gas') were converted into dummy columns and the reference columns were removed.

\newpage

## **APPENDIX A**

\newpage

## **APPENDIX B**

**Table 1 - Missing Values**

```{r missing_values, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(na_count, caption = "Missing Values in each Variable")
```

\newpage

**Table 2 - Variance Inflation Factor (VIF)**

```{r vif,echo=FALSE, warning = FALSE, message = FALSE}
kable(vif, caption = "Variance Inflation Factor (VIF) ")
```

\newpage

## **Appendix C**

\newpage

**Figure: 1 - Churn Rate**

```{r churn_rate, echo = FALSE, warning= FALSE,message= FALSE, fig.width=8,fig.height=4, fig.align="center"}
print(churn_rate_barchart)
```

**Figure: 2 - Month Duration charts**

```{r months_active_end, echo=FALSE, fig.height=4, fig.width=8, message=FALSE, warning=FALSE, fig.align="center"}
ggarrange1 <- ggarrange(months_active_barchart,months_end_barchart,months_renewal_barchart,months_modif_barchart,
          nrow = 2, ncol = 2,
          common.legend = TRUE,
          labels = c("Months Active", "Months End", "Months Renewal", "Months_modif"),
          vjust = c(-0.5,-0.5,0.4,0.4),
          hjust = c(-1.8,-2.4,-1.5,-2.0),
          font.label = list(size = 10))

annotate_figure(ggarrange1,
                bottom = text_grob("No of Months", color = "black",
                                   hjust = 4.3, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))
```

\newpage

**Figure: 3 - Consumption Variables Exploration**

```{r consumption_eda, echo = FALSE, warning = FALSE, message = FALSE, fig.align="center"}
##### CONSUMPTION VARIABLES EXPLORATORY ANALYSIS #####
annotate_figure(consumption_eda,
                bottom = text_grob("Consumption", color = "black",
                                   hjust =3.9, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))


```

**Figure: 4 - Forecast Variables Exploration**

```{r forecast_eda, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center",fig.height= 5}
annotate_figure(forecast_eda,
                bottom = text_grob("Dollars ($)", color = "black",
                                   hjust = 5, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))
```

\newpage

**Figure: 5 - Margin Variables Exploration**

```{r margin_eda, echo = FALSE, message=FALSE, warning=FALSE, fig.align="center"}
annotate_figure(margin_eda,
                bottom = text_grob("Dollars ($)", color = "black",
                                   hjust = 4.75, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))
```

**Figure: 6 - Other Variables Exploration**

```{r other_eda, echo = FALSE, message=FALSE, warning=FALSE, fig.align="center"}
annotate_figure(other_eda,
                bottom = text_grob("Value", color = "black",
                                   hjust = 8.8, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))
```

**Figure: 7 - Loess/Scatterplot of Variables**

```{r, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE}
ggpubr::ggarrange(cons_12m_sc,ln_cons_12m_sc, nrow = 1, ncol = 2)
ggpubr::ggarrange(cons_last_month_sc,ln_cons_last_month_sc, nrow = 1, ncol = 2)
ggpubr::ggarrange(imp_cons_sc,ln_imp_cons_sc, nrow = 1, ncol = 2)
ggpubr::ggarrange(cons_gas_12m_sc,ln_cons_gas_12m_sc, nrow = 1, ncol = 2)
ggpubr::ggarrange(forecast_cons_12m_sc,ln_forecast_cons_12m_sc, nrow = 1, ncol = 2)
 


#ln_cons_last_month_sc,imp_cons_sc,ln_imp_cons_sc,cons_gas_12m_sc,ln_cons_gas_12m_sc,forecast_cons_12m_sc, ln_forecast_cons_12m_sc,forecast_meter_rent_12m_sc,ln_forecast_meter_rent_12m_sc, nrow = 6, ncol = 2)

```

**Figure: 8 - Transformed Variables Exploration**

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.align="center"}
annotate_figure(transformed_eda,
                bottom = text_grob("Value", color = "black",
                                   hjust = 8.8, x = 1, size = 11, face = "bold"),
                left = text_grob("No of Companies", color = "black", rot = 90, face = "bold",size = 11))
```

**Figure 9 - Correlation Matrix**

```{r correlation_matrix_chart,echo = FALSE, warning = FALSE, message = FALSE, fig.height=10,fig.width=10, fig.align="center"}
cor_matrix + rotate_x_text(angle = 90) + font("xlab", size = 1, color = "black")+
 font("ylab", size = 1, color = "black")

```
