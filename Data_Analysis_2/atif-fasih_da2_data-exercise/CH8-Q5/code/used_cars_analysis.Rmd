---
title: "CH8_Q5"
author: "Fasih Atif"
date: "12/20/2020"
output: pdf_document
---

Our task is to analyze Price vs Age of cars to find a good car deal. For this purpose, I web scrapped data from a cars website named [truecars.com](https://www.truecar.com/) which sells used cars and is based in the United States. The brand and type of car we will use for analysis is the Ford Fusion.

![](images/2020-Ford-Fusion-FrontSide_FOFUS2001_640x480.jpg)

## **Price vs Age Analysis for Ford Fusion**

```{r, include= FALSE}

# Set Cran mirror to avoid error
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})
       
install.packages("tidyverse")
library(tidyverse)
library(data.table)
library(rvest)
library(knitr)
library(ggpubr)
library(scales)
library(estimatr)
library(lspline)
library(texreg)

urlfile <- "https://raw.githubusercontent.com/fasihatif/Data-Analysis-1-2-3/master/Data_Analysis_2/atif-fasih_da2_data-exercise/CH8-Q5/data/used_cars_ford.csv"

database <- read_csv(urlfile)

database <- database %>% mutate('age' = 2020 - make_year)

```

The top 5 rows of the cars database that we scrapped is shown below:

```{r, echo = FALSE}
head_table <- head(database)
kable(head_table)

```

## Variable Transformation

Some non linear patterns can be better approximated by linear regressions if the X or Y or both are transformed by taking logs. This is often a good choice when the data is skewed. It is important to think beforehand what kind of transformations are feasible or not. We would like a transformation that explains the association between the dependent and independent variable clearly and interpretations that make the most sense.

**Level-Level Model: price = alpha + beta\*age (Figure 1)**

**Log-Log Model: ln\_price = alpha + beta\*ln\_age (Figure 2)**

**Log-Level Model: ln\_price = alpha + beta\*age (Figure 3)**

```{r, include = FALSE}
# Level - Level
lvl_lvl <- ggplot(database, aes(x = age, y = car_price)) + geom_point() +geom_smooth(method = 'loess')

# log - log
log_log <- database %>%
  ggplot(aes(x = age, y = car_price)) + geom_point() +geom_smooth(method = 'loess') + 
  scale_y_continuous(trans = log_trans()) + scale_x_continuous(trans = log_trans()) 

# level - log
lvl_log <- database %>%
  ggplot(aes(x = age, y = car_price)) + geom_point() +geom_smooth(method = 'loess') + 
  scale_y_continuous(trans = log_trans(),breaks = c(0,2500,5000,10000,15000,20000,25000)) 
```

Based on model comparison, our chosen model is **Log-Level Model.**

• Substantive Reasoning: Price decrease is measured in percentage changes so it can be easily related with age. Our interpretations will tell us the percentage change with which prices decrease as age increases in absolute terms.\
• Statistical Reasoning: It is a linear model which is easy to interpret and captures the variation well.

## Log Transformation of variables for Regression

Based on our investigation, we found out that log transformations would work best on both dependent variable. So, we created a new log variables for car\_price named ln\_price.

```{r, include = FALSE}
database <- database %>% mutate( ln_price = log( car_price ),
                                 age_sq = age*age)
```

## Estimating different Regression models

We ran different regression models in order to try to capture the non linearity in the best we could. We used simple linear regression, quadratic regression, and piecewise linear regression to estimate. All models gave approximately the same result:

```{r, include = FALSE}
# Simple Linear Regression
linear_reg <- lm_robust( ln_price ~ age , data = database , se_type = "HC2" )

linear_reg_graph <- ggplot( data = database, aes( x = age, y = ln_price ) ) + 
  geom_point( color='blue') +
  geom_smooth( method = lm , color = 'red' )

# Quadratic Regression
quad_reg <- lm_robust( ln_price ~ age + age_sq , data = database )

quad_reg_graph <- ggplot( data = database, aes( x = age, y = ln_price) ) + 
  geom_point( color='blue') +
  geom_smooth( formula = y ~ poly(x,2) , method = lm , color = 'red' )

# Piecewise linear Spline Regression

cutoff <- 8

# Use simple regression with the lspline function
lspline_reg <- lm_robust(ln_price ~ lspline( age, cutoff ), data = database )
summary( lspline_reg  )
lspline_reg_graph <- ggplot( data = database, aes( x = age, y = ln_price ) ) + 
  geom_point( color='blue') +
  geom_smooth( formula = y ~ lspline(x,cutoff) , method = lm , color = 'red' )

```

```{r, include = FALSE}

data_out <- 'C:/Users/abc/OneDrive/Business_Analytics/Data-Analysis-1-2-3/Data_Analysis_2/atif-fasih_da2_data-exercise/CH8-Q5/docs/'
  
texreg( list(linear_reg , quad_reg , lspline_reg),
         type = 'html',
         custom.model.names = c("ln_price - linear","ln_price - quadratic",
                                "ln_spline - PLS"),
         caption = "Modelling Price vs Age of Cars",
         file = paste0( data_out ,'model_comparison.html'), include.ci = FALSE)

```

![](C:/Users/abc/AppData/Local/RStudio/tmp/paste-7073225E.png){width="523"}

The model that i think is the best is the simple linear regression. It has the same result as other models and is simple to use.

## Interpretation

**Beta**: Car price decreases by 11% as age increases by 1.

## **Residual Analysis**

We can use our residual results to find the best deals. The most lowest and negative residuals will be the best car deals for us. The best deals are shown below:

```{r, echo = FALSE}

# Get the predicted y values from the model
database$linear_reg_y_pred <- linear_reg$fitted.values
# Calculate the errors of the model
database$linear_reg_res <- database$ln_price - database$linear_reg_y_pred 

# Find countries with largest negative errors
best_deal <- database%>% top_n( -5 , linear_reg_res ) %>% 
  select( model_name , make_year , car_description, car_colour, location, car_price, linear_reg_res )

library(knitr)
kable(best_deal)

```

\newpage

## Appendix

### Figure 1

```{r, echo = FALSE, warning= FALSE, message= FALSE,fig.height= 4}
lvl_lvl

```

### Figure 2

```{r, echo = FALSE, warning= FALSE, message= FALSE, fig.height= 4}
log_log
```

### Figure 3

```{r, echo = FALSE, warning= FALSE, message= FALSE,fig.height= 4}
lvl_log
```

### Figure 4

```{r, echo = FALSE, warning= FALSE, message= FALSE,fig.height= 4}
linear_reg_graph
```

### Figure 5

```{r, echo = FALSE, warning= FALSE, message= FALSE, fig.height= 4}
quad_reg_graph
```

### Figure 6

```{r, echo = FALSE, warning= FALSE, message= FALSE, fig.height= 4}
lspline_reg_graph
```
